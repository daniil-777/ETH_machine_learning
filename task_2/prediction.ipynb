{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import pandas as pd\n",
    "from sklearn import svm, model_selection, metrics, linear_model, tree\n",
    "from statsmodels.tsa.statespace.varmax import VARMAX\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, IsolationForest\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import RobustScaler, FunctionTransformer\n",
    "from sklearn.svm import SVC, SVR, LinearSVR\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.feature_selection import SelectPercentile, SelectKBest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "import sklearn.feature_selection as feature_selection\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "# from mice import Mice\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "#new packages\n",
    "# from fancyimpute import KNN, NuclearNormMinimization, SoftImpute, BiScaler\n",
    "# from sklearn.impute import KNNImputer\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import make_column_transformer, ColumnTransformer\n",
    "from matplotlib.pyplot import figure\n",
    "from numpy import savetxt\n",
    "from numpy import loadtxt\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn import svm\n",
    "import mlxtend\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "import my_utils\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, ComplementNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "import logging\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "import sysss\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import lightgbm\n",
    "# Display progress logs on stdout\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################LAbels of Tests###############################\n",
    "TESTS = ['LABEL_BaseExcess', 'LABEL_Fibrinogen', 'LABEL_AST', 'LABEL_Alkalinephos', 'LABEL_Bilirubin_total',\n",
    "         'LABEL_Lactate', 'LABEL_TroponinI', 'LABEL_SaO2',\n",
    "         'LABEL_Bilirubin_direct', 'LABEL_EtCO2']\n",
    "\n",
    "VITALS = ['LABEL_RRate', 'LABEL_ABPm', 'LABEL_SpO2', 'LABEL_Heartrate']\n",
    "\n",
    "path_train_features = \"data/train_features.csv\"\n",
    "path_train_labels = \"data/train_labels.csv\"\n",
    "path_test_features = \"data/test_features.csv\"\n",
    "x_test_raw = pd.read_csv(path_test_features)\n",
    "\n",
    "\n",
    "columns_labels_first = [\"BaseExcess\", \"Fibrinogen\", \"AST\", \"Alkalinephos\", \"Bilirubin_total\", \"Lactate\", \"TroponinI\", \"SaO2\", \"Bilirubin_direct\", \"EtCO2\"]\n",
    "columns_labels_second = [\"Sepsis\"]\n",
    "columns_labels_third = [\"RRate\", \"ABPm\", \"SpO2\", \"Heartrate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading imputed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = pd.read_csv('train_eng_features.csv', index_col=0)\n",
    "# x_test = pd.read_csv('test_eng_features.csv', index_col=0)\n",
    "\n",
    "x_train = pd.read_csv('train_all_eng_features.csv', index_col=0)\n",
    "x_test = pd.read_csv('test_all_eng_features.csv', index_col=0)\n",
    "\n",
    "pids = np.unique(x_test['pid'].to_numpy())\n",
    "x_train = x_train.drop(['pid'], axis = 1)\n",
    "x_test = x_test.drop(['pid'], axis = 1)\n",
    "\n",
    "y_train_labels = pd.read_csv(path_train_labels)\n",
    "\n",
    "y_train_labels_sorted = y_train_labels.sort_values('pid')\n",
    "\n",
    "y_train_labels = y_train_labels.drop(['pid'], axis = 1)\n",
    "\n",
    "y_sepsis = y_train_labels_sorted['LABEL_Sepsis'].to_numpy()\n",
    "\n",
    "#Dataframe for predicted data\n",
    "columns_predicted = ['pid'] + TESTS + ['LABEL_Sepsis'] + VITALS \n",
    "predicted_y_df = pd.DataFrame(columns = columns_predicted)\n",
    "predicted_y_df['pid'] = pids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Not_none_BaseExcess', 'BaseExcess', 'Not_none_Fibrinogen',\n",
       "       'Fibrinogen', 'Not_none_AST', 'AST', 'Not_none_Alkalinephos',\n",
       "       'Alkalinephos', 'Not_none_Bilirubin_total',\n",
       "       ...\n",
       "       'Min_RRate', 'Max_RRate', 'Min_ABPm', 'Max_ABPm', 'Min_SpO2',\n",
       "       'Max_SpO2', 'Min_Heartrate', 'Max_Heartrate', 'custom_age',\n",
       "       'custom_hr'],\n",
       "      dtype='object', length=105)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = ['custom_age','custom_hr']\n",
    "indexes_of_categories = [x_test.columns.get_loc(col) for col in categoricals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[103, 104]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes_of_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline for the first subtask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SelectPercentile(percentile=100)\n",
    "#svc = SVC(C=1, kernel='rbf', class_weight='balanced', probability = True, random_state=42)\n",
    "logreg = LogisticRegression()\n",
    "lbm = LGBMClassifier(reg_alpha=15, reg_ambda=15, n_estimators=100)\n",
    "pipeline = make_pipeline(selector, lbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation\n",
    "score_summary = []\n",
    "for i in range(len(y1_label)):\n",
    "    print(\"Feature: {}\".format(y1_label[i]))\n",
    "    scores = cross_validate(pipeline, x_train, y1[:,i],\n",
    "                                scoring='roc_auc',\n",
    "                                return_train_score=True,\n",
    "                                cv=5,  # Already include stratified folds\n",
    "                                return_estimator=True,\n",
    "                                n_jobs=-1)  # Add parallelism to speed up validation\n",
    "    print(\"Test scores:\\t\", scores['test_score'],\n",
    "            '\\nTrain scores:\\t', scores['train_score'])\n",
    "    print(\"Test: %0.4f (+/- %0.4f)\" % (scores['test_score'].mean(), scores['test_score'].std() * 2))\n",
    "    score_summary.append(scores['test_score'].mean())\n",
    "    print(\"Train: %0.4f (+/- %0.4f)\" % (scores['train_score'].mean(), scores['train_score'].std() * 2))\n",
    "\n",
    "    pipeline.fit(x_train, y1[:,i])\n",
    "    y_pred = pipeline.predict_proba(x_test)[:,1]\n",
    "    \n",
    "    prediction[y1_label[i]] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: LABEL_BaseExcess\n",
      "Test scores:\t [0.94138814 0.93319625 0.93281359 0.93380589 0.93351678] \n",
      "Train scores:\t [0.95994345 0.96172565 0.96212669 0.96172702 0.96202612]\n",
      "Test: 0.9349 (+/- 0.0065)\n",
      "Train: 0.9615 (+/- 0.0016)\n",
      "[0.7791249  0.04918571 0.04639729 ... 0.77088615 0.00986367 0.06241249]\n",
      "Feature: LABEL_Fibrinogen\n",
      "Test scores:\t [0.81037024 0.82609305 0.79898307 0.83481001 0.80527138] \n",
      "Train scores:\t [0.92608207 0.9237107  0.92583209 0.92349636 0.91855895]\n",
      "Test: 0.8151 (+/- 0.0267)\n",
      "Train: 0.9235 (+/- 0.0054)\n",
      "[0.29217899 0.03185164 0.02799966 ... 0.05049368 0.01165053 0.08255228]\n",
      "Feature: LABEL_AST\n",
      "Test scores:\t [0.75087239 0.75995033 0.76225366 0.76336124 0.76061168] \n",
      "Train scores:\t [0.86155535 0.86037443 0.86113822 0.86085921 0.86060552]\n",
      "Test: 0.7594 (+/- 0.0089)\n",
      "Train: 0.8609 (+/- 0.0008)\n",
      "[0.86787351 0.2251164  0.13108434 ... 0.18746772 0.27403682 0.43396172]\n",
      "Feature: LABEL_Alkalinephos\n",
      "Test scores:\t [0.75721353 0.76360055 0.76907173 0.76734426 0.76394401] \n",
      "Train scores:\t [0.86448563 0.86284738 0.86139068 0.86324439 0.86206571]\n",
      "Test: 0.7642 (+/- 0.0081)\n",
      "Train: 0.8628 (+/- 0.0021)\n",
      "[0.84706341 0.24794317 0.11948213 ... 0.17639782 0.21994382 0.37287775]\n",
      "Feature: LABEL_Bilirubin_total\n",
      "Test scores:\t [0.75036653 0.75898122 0.76477669 0.76128659 0.76177846] \n",
      "Train scores:\t [0.86386989 0.86225855 0.86141641 0.86168097 0.86145488]\n",
      "Test: 0.7594 (+/- 0.0098)\n",
      "Train: 0.8621 (+/- 0.0018)\n",
      "[0.86327338 0.24915391 0.15295241 ... 0.21006344 0.24114482 0.39587276]\n",
      "Feature: LABEL_Lactate\n",
      "Test scores:\t [0.8180701  0.80288661 0.83218176 0.81719056 0.81969095] \n",
      "Train scores:\t [0.8970534  0.8980093  0.89463273 0.89577268 0.89497696]\n",
      "Test: 0.8180 (+/- 0.0186)\n",
      "Train: 0.8961 (+/- 0.0025)\n",
      "[0.39231511 0.08025493 0.04666966 ... 0.23104454 0.06042685 0.110732  ]\n",
      "Feature: LABEL_TroponinI\n",
      "Test scores:\t [0.90913299 0.90478637 0.90813776 0.90105078 0.89886667] \n",
      "Train scores:\t [0.94976296 0.95091557 0.94860658 0.95086548 0.95232954]\n",
      "Test: 0.9044 (+/- 0.0079)\n",
      "Train: 0.9505 (+/- 0.0025)\n",
      "[0.01881681 0.06414879 0.06677687 ... 0.00951417 0.16759175 0.87487144]\n",
      "Feature: LABEL_SaO2\n",
      "Test scores:\t [0.83886255 0.84079919 0.85914797 0.84008893 0.83715002] \n",
      "Train scores:\t [0.90751162 0.90881713 0.90420928 0.90833441 0.91015101]\n",
      "Test: 0.8432 (+/- 0.0161)\n",
      "Train: 0.9078 (+/- 0.0040)\n",
      "[0.22585479 0.07549584 0.06223958 ... 0.29852859 0.05251771 0.13955107]\n",
      "Feature: LABEL_Bilirubin_direct\n",
      "Test scores:\t [0.76974087 0.78269227 0.81273684 0.76252878 0.74350168] \n",
      "Train scores:\t [0.91554163 0.91805299 0.91902433 0.92444392 0.92644267]\n",
      "Test: 0.7742 (+/- 0.0461)\n",
      "Train: 0.9207 (+/- 0.0082)\n",
      "[0.08599674 0.01223668 0.0128574  ... 0.01110918 0.0361346  0.06356951]\n",
      "Feature: LABEL_EtCO2\n",
      "Test scores:\t [0.93662778 0.9519981  0.94166513 0.94184592 0.95328494] \n",
      "Train scores:\t [0.98086838 0.98050603 0.98157279 0.97895519 0.97962872]\n",
      "Test: 0.9451 (+/- 0.0129)\n",
      "Train: 0.9803 (+/- 0.0018)\n",
      "[0.01183599 0.0100611  0.00710839 ... 0.00566815 0.05174575 0.04620027]\n"
     ]
    }
   ],
   "source": [
    "score_summary = []\n",
    "for label in TESTS:\n",
    "    y_train = y_train_labels_sorted[label].to_numpy()\n",
    "    print(\"Feature: {}\".format(label))\n",
    "    scores = cross_validate(pipeline, x_train, y_train,\n",
    "                                scoring='roc_auc',\n",
    "                                return_train_score=True,\n",
    "                                cv=5,  # Already include stratified folds\n",
    "                                return_estimator=True,\n",
    "                                n_jobs=-1)  # Add parallelism to speed up validation\n",
    "    print(\"Test scores:\\t\", scores['test_score'],\n",
    "            '\\nTrain scores:\\t', scores['train_score'])\n",
    "    print(\"Test: %0.4f (+/- %0.4f)\" % (scores['test_score'].mean(), scores['test_score'].std() * 2))\n",
    "    score_summary.append(scores['test_score'].mean())\n",
    "    print(\"Train: %0.4f (+/- %0.4f)\" % (scores['train_score'].mean(), scores['train_score'].std() * 2))\n",
    "\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    y_pred = pipeline.predict_proba(x_test)[:,1]\n",
    "    print(y_pred)\n",
    "    \n",
    "    predicted_y_df[label] = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: LABEL_Sepsis\n",
      "Test scores:\t [0.76092958 0.72519278 0.74563125 0.73858847 0.77023613] \n",
      "Train scores:\t [0.94913423 0.95106762 0.95232501 0.95048036 0.94987139]\n",
      "Test: 0.7481 (+/- 0.0319)\n",
      "Train: 0.9506 (+/- 0.0022)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniil/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py:842: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "  .format(key))\n"
     ]
    }
   ],
   "source": [
    "label = 'LABEL_Sepsis'\n",
    "selector = SelectPercentile(percentile=100)\n",
    "#svc = SVC(C=1, kernel='rbf', class_weight='balanced', probability = True, random_state=42)\n",
    "logreg = LogisticRegression()\n",
    "lbm = LGBMClassifier(reg_alpha=41, reg_ambda=15, n_estimators=100, categorical_feature=indexes_of_categories, class_weight='balanced')\n",
    "pipeline = make_pipeline(selector, lbm)\n",
    "\n",
    "i= -1\n",
    "print(\"Feature: {}\".format(label))\n",
    "scores = cross_validate(pipeline, x_train, y_sepsis,\n",
    "                            scoring='roc_auc',\n",
    "                            return_train_score=True,\n",
    "                            cv=5,  # Already include stratified folds\n",
    "                            return_estimator=True,\n",
    "                            n_jobs=-1)  # Add parallelism to speed up validation\n",
    "print(\"Test scores:\\t\", scores['test_score'],\n",
    "        '\\nTrain scores:\\t', scores['train_score'])\n",
    "print(\"Test: %0.4f (+/- %0.4f)\" % (scores['test_score'].mean(), scores['test_score'].std() * 2))\n",
    "score_summary[-1] = scores['test_score'].mean()\n",
    "print(\"Train: %0.4f (+/- %0.4f)\" % (scores['train_score'].mean(), scores['train_score'].std() * 2))\n",
    "\n",
    "pipeline.fit(x_train, y_sepsis)\n",
    "y_pred = pipeline.predict_proba(x_test)[:,1]\n",
    "\n",
    "predicted_y_df[label] = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label_RRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: LABEL_RRate\n",
      "Test scores:\t [0.4092498  0.43811892 0.42554614 0.39532946 0.41999501] \n",
      "Train scores:\t [0.47227027 0.46783068 0.46968236 0.47807343 0.47374423]\n",
      "Test: 0.4176 (+/- 0.0291)\n",
      "Train: 0.4723 (+/- 0.0071)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.feature_selection as feature_selection\n",
    "\n",
    "label = VITALS[0]\n",
    "y_train = y_train_labels_sorted[label].to_numpy()\n",
    "\n",
    "\n",
    "selector = SelectPercentile(feature_selection.f_regression, percentile=50)\n",
    "\n",
    "params = {'n_estimators': 500,\n",
    "              'max_depth': 10,\n",
    "              'learning_rate': 0.1,\n",
    "              'loss': 'ls'}\n",
    "            \n",
    "scaler = StandardScaler()\n",
    "gbr = GradientBoostingRegressor(n_estimators = 100, max_depth=3, max_features=None)\n",
    "lsvr = LinearSVR()\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(100, 100, 100, ))\n",
    "lgreg = LGBMRegressor(reg_alpha=200, reg_lambda=100, n_estimators=200)\n",
    "pipeline = make_pipeline(selector, gbr)\n",
    "\n",
    "i = 0\n",
    "print(\"Feature: {}\".format(label))\n",
    "scores = cross_validate(pipeline, x_train, y_train,\n",
    "                            scoring='r2',\n",
    "                            return_train_score=True,\n",
    "                            cv=5,  # Already include stratified folds\n",
    "                            return_estimator=True,\n",
    "                            n_jobs=-1)  # Add parallelism to speed up validation\n",
    "print(\"Test scores:\\t\", scores['test_score'],\n",
    "          '\\nTrain scores:\\t', scores['train_score'])\n",
    "print(\"Test: %0.4f (+/- %0.4f)\" % (scores['test_score'].mean(), scores['test_score'].std() * 2))\n",
    "print(\"Train: %0.4f (+/- %0.4f)\" % (scores['train_score'].mean(), scores['train_score'].std() * 2))\n",
    "\n",
    "pipeline.fit(x_train, y_train)\n",
    "y_pred = pipeline.predict(x_test)\n",
    "predicted_y_df[label] = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LABEL_ABPm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: LABEL_ABPm\n",
      "Test scores:\t [0.62901594 0.61311909 0.62465691 0.63330508 0.61039418] \n",
      "Train scores:\t [0.71783087 0.72259015 0.72069636 0.71834677 0.72234091]\n",
      "Test: 0.6221 (+/- 0.0178)\n",
      "Train: 0.7204 (+/- 0.0039)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "label = VITALS[1]\n",
    "y_train = y_train_labels_sorted[label].to_numpy()\n",
    "\n",
    "\n",
    "selector = SelectPercentile(feature_selection.f_regression, percentile=90)\n",
    "params = {'n_estimators': 500,\n",
    "              'max_depth': 10,\n",
    "              'learning_rate': 0.1,\n",
    "              'loss': 'ls'}\n",
    "#iforest = IsolationForest()              \n",
    "scaler = StandardScaler()\n",
    "gbr = GradientBoostingRegressor(n_estimators = 200, max_depth=5, max_features=None)\n",
    "lsvr = LinearSVR()\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(100, 100, 100, ))\n",
    "lgreg = LGBMRegressor(reg_alpha=200, reg_lambda=100, n_estimators=200)\n",
    "pipeline = make_pipeline(selector, lgreg)\n",
    "\n",
    "i = 1\n",
    "print(\"Feature: {}\".format(label))\n",
    "scores = cross_validate(pipeline, x_train, y_train,\n",
    "                            scoring='r2',\n",
    "                            return_train_score=True,\n",
    "                            cv=5,  # Already include stratified folds\n",
    "                            return_estimator=True,\n",
    "                            n_jobs=-1)  # Add parallelism to speed up validation\n",
    "print(\"Test scores:\\t\", scores['test_score'],\n",
    "          '\\nTrain scores:\\t', scores['train_score'])\n",
    "print(\"Test: %0.4f (+/- %0.4f)\" % (scores['test_score'].mean(), scores['test_score'].std() * 2))\n",
    "print(\"Train: %0.4f (+/- %0.4f)\" % (scores['train_score'].mean(), scores['train_score'].std() * 2))\n",
    "\n",
    "pipeline.fit(x_train, y_train)\n",
    "y_pred = pipeline.predict(x_test)\n",
    "predicted_y_df[label] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18995, 37)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LABEL_SpO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: LABEL_SpO2\n",
      "Test scores:\t [0.39758259 0.3411529  0.38304721 0.35230138 0.3627477 ] \n",
      "Train scores:\t [0.54878741 0.54669972 0.54455542 0.55916429 0.50326439]\n",
      "Test: 0.3674 (+/- 0.0409)\n",
      "Train: 0.5405 (+/- 0.0386)\n"
     ]
    }
   ],
   "source": [
    "label = VITALS[2]\n",
    "y_train = y_train_labels_sorted[label].to_numpy()\n",
    "\n",
    "\n",
    "selector = SelectPercentile(feature_selection.f_regression, percentile=50)\n",
    "ridge = Ridge(alpha=500.0)\n",
    "gbr = GradientBoostingRegressor(n_estimators = 100, max_depth=3, max_features=50)\n",
    "lsvr = LinearSVR()\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(100, 100, 100, ))\n",
    "lgreg = LGBMRegressor(reg_alpha=100, reg_lambda=100, n_estimators=600)\n",
    "pipeline = make_pipeline(gbr)\n",
    "\n",
    "i = 2\n",
    "print(\"Feature: {}\".format(label))\n",
    "scores = cross_validate(pipeline, x_train, y_train,\n",
    "                            scoring='r2',\n",
    "                            return_train_score=True,\n",
    "                            cv=5,  # Already include stratified folds\n",
    "                            return_estimator=True,\n",
    "                            n_jobs=-1)  # Add parallelism to speed up validation\n",
    "print(\"Test scores:\\t\", scores['test_score'],\n",
    "          '\\nTrain scores:\\t', scores['train_score'])\n",
    "print(\"Test: %0.4f (+/- %0.4f)\" % (scores['test_score'].mean(), scores['test_score'].std() * 2))\n",
    "print(\"Train: %0.4f (+/- %0.4f)\" % (scores['train_score'].mean(), scores['train_score'].std() * 2))\n",
    "\n",
    "pipeline.fit(x_train, y_train)\n",
    "y_pred = pipeline.predict(x_test)\n",
    "predicted_y_df[label] = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LABEL_Heartrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: LABEL_Heartrate\n",
      "Test scores:\t [0.6383928  0.63884464 0.63502804 0.63563838 0.61829668] \n",
      "Train scores:\t [0.66192627 0.66077355 0.66095476 0.66191912 0.66708885]\n",
      "Test: 0.6332 (+/- 0.0152)\n",
      "Train: 0.6625 (+/- 0.0047)\n"
     ]
    }
   ],
   "source": [
    "selector = SelectPercentile(feature_selection.f_regression, percentile=80)\n",
    "\n",
    "label = VITALS[3]\n",
    "y_train = y_train_labels_sorted[label].to_numpy()\n",
    "\n",
    "params = {'n_estimators': 500,\n",
    "              'max_depth': 10,\n",
    "              'learning_rate': 0.1,\n",
    "              'loss': 'ls'}\n",
    "#iforest = IsolationForest()              \n",
    "scaler = StandardScaler()\n",
    "ridge = Ridge(alpha=0.1)\n",
    "gbr = GradientBoostingRegressor(n_estimators = 100, max_depth=3, max_features=None)\n",
    "lsvr = LinearSVR()\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(100, 100, 100, ))\n",
    "lgreg = LGBMRegressor(reg_alpha=100, reg_lambda=100, n_estimators=500)\n",
    "pipeline = make_pipeline(selector, gbr)\n",
    "\n",
    "i = 3\n",
    "print(\"Feature: {}\".format(label))\n",
    "scores = cross_validate(pipeline, x_train, y_train,\n",
    "                            scoring='r2',\n",
    "                            return_train_score=True,\n",
    "                            cv=5,  # Already include stratified folds\n",
    "                            return_estimator=True,\n",
    "                            n_jobs=-1)  # Add parallelism to speed up validation\n",
    "print(\"Test scores:\\t\", scores['test_score'],\n",
    "          '\\nTrain scores:\\t', scores['train_score'])\n",
    "print(\"Test: %0.4f (+/- %0.4f)\" % (scores['test_score'].mean(), scores['test_score'].std() * 2))\n",
    "print(\"Train: %0.4f (+/- %0.4f)\" % (scores['train_score'].mean(), scores['train_score'].std() * 2))\n",
    "\n",
    "pipeline.fit(x_train, y_train)\n",
    "y_pred = pipeline.predict(x_test)\n",
    "predicted_y_df[label] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>LABEL_BaseExcess</th>\n",
       "      <th>LABEL_Fibrinogen</th>\n",
       "      <th>LABEL_AST</th>\n",
       "      <th>LABEL_Alkalinephos</th>\n",
       "      <th>LABEL_Bilirubin_total</th>\n",
       "      <th>LABEL_Lactate</th>\n",
       "      <th>LABEL_TroponinI</th>\n",
       "      <th>LABEL_SaO2</th>\n",
       "      <th>LABEL_Bilirubin_direct</th>\n",
       "      <th>LABEL_EtCO2</th>\n",
       "      <th>LABEL_Sepsis</th>\n",
       "      <th>LABEL_RRate</th>\n",
       "      <th>LABEL_ABPm</th>\n",
       "      <th>LABEL_SpO2</th>\n",
       "      <th>LABEL_Heartrate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.779125</td>\n",
       "      <td>0.292179</td>\n",
       "      <td>0.867874</td>\n",
       "      <td>0.847063</td>\n",
       "      <td>0.863273</td>\n",
       "      <td>0.392315</td>\n",
       "      <td>0.018817</td>\n",
       "      <td>0.225855</td>\n",
       "      <td>0.085997</td>\n",
       "      <td>0.011836</td>\n",
       "      <td>0.561805</td>\n",
       "      <td>14.977656</td>\n",
       "      <td>85.405563</td>\n",
       "      <td>98.905119</td>\n",
       "      <td>85.192550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.049186</td>\n",
       "      <td>0.031852</td>\n",
       "      <td>0.225116</td>\n",
       "      <td>0.247943</td>\n",
       "      <td>0.249154</td>\n",
       "      <td>0.080255</td>\n",
       "      <td>0.064149</td>\n",
       "      <td>0.075496</td>\n",
       "      <td>0.012237</td>\n",
       "      <td>0.010061</td>\n",
       "      <td>0.243430</td>\n",
       "      <td>17.595135</td>\n",
       "      <td>83.614474</td>\n",
       "      <td>96.540629</td>\n",
       "      <td>96.236992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.046397</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>0.131084</td>\n",
       "      <td>0.119482</td>\n",
       "      <td>0.152952</td>\n",
       "      <td>0.046670</td>\n",
       "      <td>0.066777</td>\n",
       "      <td>0.062240</td>\n",
       "      <td>0.012857</td>\n",
       "      <td>0.007108</td>\n",
       "      <td>0.054393</td>\n",
       "      <td>18.605545</td>\n",
       "      <td>71.688024</td>\n",
       "      <td>95.612272</td>\n",
       "      <td>68.027369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0.851429</td>\n",
       "      <td>0.868930</td>\n",
       "      <td>0.909960</td>\n",
       "      <td>0.921863</td>\n",
       "      <td>0.929100</td>\n",
       "      <td>0.446534</td>\n",
       "      <td>0.009882</td>\n",
       "      <td>0.787962</td>\n",
       "      <td>0.586376</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.527856</td>\n",
       "      <td>17.734102</td>\n",
       "      <td>88.982783</td>\n",
       "      <td>98.052140</td>\n",
       "      <td>88.654790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0.109900</td>\n",
       "      <td>0.067852</td>\n",
       "      <td>0.194010</td>\n",
       "      <td>0.146289</td>\n",
       "      <td>0.171612</td>\n",
       "      <td>0.072729</td>\n",
       "      <td>0.005739</td>\n",
       "      <td>0.047883</td>\n",
       "      <td>0.011993</td>\n",
       "      <td>0.001653</td>\n",
       "      <td>0.198055</td>\n",
       "      <td>20.199041</td>\n",
       "      <td>89.512577</td>\n",
       "      <td>96.229560</td>\n",
       "      <td>91.404952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12659</th>\n",
       "      <td>31647</td>\n",
       "      <td>0.055201</td>\n",
       "      <td>0.027096</td>\n",
       "      <td>0.125205</td>\n",
       "      <td>0.113107</td>\n",
       "      <td>0.125585</td>\n",
       "      <td>0.031431</td>\n",
       "      <td>0.012443</td>\n",
       "      <td>0.025629</td>\n",
       "      <td>0.022503</td>\n",
       "      <td>0.003095</td>\n",
       "      <td>0.081701</td>\n",
       "      <td>16.375573</td>\n",
       "      <td>67.457490</td>\n",
       "      <td>97.090322</td>\n",
       "      <td>72.045198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12660</th>\n",
       "      <td>31649</td>\n",
       "      <td>0.908318</td>\n",
       "      <td>0.068362</td>\n",
       "      <td>0.549797</td>\n",
       "      <td>0.470570</td>\n",
       "      <td>0.414453</td>\n",
       "      <td>0.721192</td>\n",
       "      <td>0.012266</td>\n",
       "      <td>0.313300</td>\n",
       "      <td>0.010657</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>0.315462</td>\n",
       "      <td>16.147201</td>\n",
       "      <td>81.828445</td>\n",
       "      <td>96.570712</td>\n",
       "      <td>89.808502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12661</th>\n",
       "      <td>31651</td>\n",
       "      <td>0.770886</td>\n",
       "      <td>0.050494</td>\n",
       "      <td>0.187468</td>\n",
       "      <td>0.176398</td>\n",
       "      <td>0.210063</td>\n",
       "      <td>0.231045</td>\n",
       "      <td>0.009514</td>\n",
       "      <td>0.298529</td>\n",
       "      <td>0.011109</td>\n",
       "      <td>0.005668</td>\n",
       "      <td>0.383684</td>\n",
       "      <td>18.183495</td>\n",
       "      <td>78.376061</td>\n",
       "      <td>98.761078</td>\n",
       "      <td>85.922300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12662</th>\n",
       "      <td>31652</td>\n",
       "      <td>0.009864</td>\n",
       "      <td>0.011651</td>\n",
       "      <td>0.274037</td>\n",
       "      <td>0.219944</td>\n",
       "      <td>0.241145</td>\n",
       "      <td>0.060427</td>\n",
       "      <td>0.167592</td>\n",
       "      <td>0.052518</td>\n",
       "      <td>0.036135</td>\n",
       "      <td>0.051746</td>\n",
       "      <td>0.210631</td>\n",
       "      <td>19.286435</td>\n",
       "      <td>91.653622</td>\n",
       "      <td>97.867316</td>\n",
       "      <td>112.325948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12663</th>\n",
       "      <td>31655</td>\n",
       "      <td>0.062412</td>\n",
       "      <td>0.082552</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>0.372878</td>\n",
       "      <td>0.395873</td>\n",
       "      <td>0.110732</td>\n",
       "      <td>0.874871</td>\n",
       "      <td>0.139551</td>\n",
       "      <td>0.063570</td>\n",
       "      <td>0.046200</td>\n",
       "      <td>0.311914</td>\n",
       "      <td>17.570540</td>\n",
       "      <td>83.499948</td>\n",
       "      <td>99.151783</td>\n",
       "      <td>102.956013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12664 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pid  LABEL_BaseExcess  LABEL_Fibrinogen  LABEL_AST  \\\n",
       "0          0          0.779125          0.292179   0.867874   \n",
       "1          3          0.049186          0.031852   0.225116   \n",
       "2          5          0.046397          0.028000   0.131084   \n",
       "3          7          0.851429          0.868930   0.909960   \n",
       "4          9          0.109900          0.067852   0.194010   \n",
       "...      ...               ...               ...        ...   \n",
       "12659  31647          0.055201          0.027096   0.125205   \n",
       "12660  31649          0.908318          0.068362   0.549797   \n",
       "12661  31651          0.770886          0.050494   0.187468   \n",
       "12662  31652          0.009864          0.011651   0.274037   \n",
       "12663  31655          0.062412          0.082552   0.433962   \n",
       "\n",
       "       LABEL_Alkalinephos  LABEL_Bilirubin_total  LABEL_Lactate  \\\n",
       "0                0.847063               0.863273       0.392315   \n",
       "1                0.247943               0.249154       0.080255   \n",
       "2                0.119482               0.152952       0.046670   \n",
       "3                0.921863               0.929100       0.446534   \n",
       "4                0.146289               0.171612       0.072729   \n",
       "...                   ...                    ...            ...   \n",
       "12659            0.113107               0.125585       0.031431   \n",
       "12660            0.470570               0.414453       0.721192   \n",
       "12661            0.176398               0.210063       0.231045   \n",
       "12662            0.219944               0.241145       0.060427   \n",
       "12663            0.372878               0.395873       0.110732   \n",
       "\n",
       "       LABEL_TroponinI  LABEL_SaO2  LABEL_Bilirubin_direct  LABEL_EtCO2  \\\n",
       "0             0.018817    0.225855                0.085997     0.011836   \n",
       "1             0.064149    0.075496                0.012237     0.010061   \n",
       "2             0.066777    0.062240                0.012857     0.007108   \n",
       "3             0.009882    0.787962                0.586376     0.004451   \n",
       "4             0.005739    0.047883                0.011993     0.001653   \n",
       "...                ...         ...                     ...          ...   \n",
       "12659         0.012443    0.025629                0.022503     0.003095   \n",
       "12660         0.012266    0.313300                0.010657     0.005714   \n",
       "12661         0.009514    0.298529                0.011109     0.005668   \n",
       "12662         0.167592    0.052518                0.036135     0.051746   \n",
       "12663         0.874871    0.139551                0.063570     0.046200   \n",
       "\n",
       "       LABEL_Sepsis  LABEL_RRate  LABEL_ABPm  LABEL_SpO2  LABEL_Heartrate  \n",
       "0          0.561805    14.977656   85.405563   98.905119        85.192550  \n",
       "1          0.243430    17.595135   83.614474   96.540629        96.236992  \n",
       "2          0.054393    18.605545   71.688024   95.612272        68.027369  \n",
       "3          0.527856    17.734102   88.982783   98.052140        88.654790  \n",
       "4          0.198055    20.199041   89.512577   96.229560        91.404952  \n",
       "...             ...          ...         ...         ...              ...  \n",
       "12659      0.081701    16.375573   67.457490   97.090322        72.045198  \n",
       "12660      0.315462    16.147201   81.828445   96.570712        89.808502  \n",
       "12661      0.383684    18.183495   78.376061   98.761078        85.922300  \n",
       "12662      0.210631    19.286435   91.653622   97.867316       112.325948  \n",
       "12663      0.311914    17.570540   83.499948   99.151783       102.956013  \n",
       "\n",
       "[12664 rows x 16 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y_df.to_csv('prediction_06.06.zip', index=False, float_format='%.3f', compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
